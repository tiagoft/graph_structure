{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from transformers import AutoTokenizer, CLIPTextModelWithProjection\n",
    "from transformers import AutoProcessor, CLIPVisionModelWithProjection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.stats as st \n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin, pairwise_distances\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(x, self_is_neighbor = False):\n",
    "    D = pairwise_distances(x, x, metric='cosine')\n",
    "    if self_is_neighbor == False:\n",
    "        np.fill_diagonal(D, np.inf)\n",
    "    closest = np.argsort(D, axis=1)\n",
    "    return closest\n",
    "\n",
    "def mean_neighborhood_similarity(A, B, k):\n",
    "    \"\"\"\n",
    "    This is $D_g(A, B, k)$\n",
    "    \"\"\"\n",
    "    nx = nearest_neighbors(A)\n",
    "    ny = nearest_neighbors(B)\n",
    "    inter = 0\n",
    "    for i in range(A.shape[0]):\n",
    "        sx = set(nx[i, 0:k])\n",
    "        sy = set(ny[i, 0:k])\n",
    "        inter += len(sx.intersection(sy))/len(sx.union(sy)) # Jaccard distance\n",
    "    inter /= A.shape[0]\n",
    "    return inter\n",
    "\n",
    "def mean_neighborhood_distance(A, B, k):\n",
    "    \"\"\"\n",
    "    This is $D_g(A, B, k)$\n",
    "    \"\"\"\n",
    "    inter = 1-mean_neighborhood_similarity(A,B,k)\n",
    "    return inter\n",
    "\n",
    "def mean_structural_distance(A, B):\n",
    "    \"\"\"\n",
    "    This is $S_g(A, B)$\n",
    "    \"\"\"\n",
    "    k_vals = np.array(list(range(1, A.shape[0]-1)))\n",
    "    ns = np.array([mean_neighborhood_distance(A, B, k) for k in k_vals])\n",
    "    \n",
    "    msd = np.max((1-ns))\n",
    "    return msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = [-40, -20, 0, 10, 30, 60] #Db\n",
    "labels = [str(s) + ' dB' for s in snrs]\n",
    "ks = range(1, n_samples)\n",
    "curves = []\n",
    "for snr in snrs:\n",
    "    alpha = 10**(-snr/20)\n",
    "    res = []\n",
    "    for k in tqdm(ks):\n",
    "        if k == 0:\n",
    "            res.append(0)\n",
    "            continue\n",
    "\n",
    "        x = np.random.randn( n_samples, dim)\n",
    "        y = x + alpha*(np.random.randn(n_samples, dim))       \n",
    "        res.append(mean_neighborhood_similarity(x, y, k))\n",
    "        \n",
    "    curves.append(res)\n",
    "curves=np.array(curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_curves(seed):\n",
    "    snrs = [-40, -20, 0, 10, 30, 60] #Db\n",
    "    labels = [str(s) + ' dB' for s in snrs]\n",
    "    ks = range(1, n_samples)\n",
    "    curves = []\n",
    "    np.random.seed(seed)\n",
    "    for snr in snrs:\n",
    "        alpha = 10**(-snr/20)\n",
    "        res = []\n",
    "        for k in ks:\n",
    "            if k == 0:\n",
    "                res.append(0)\n",
    "                continue\n",
    "\n",
    "            x = np.random.randn( n_samples, dim)\n",
    "            y = x + alpha*(np.random.randn(n_samples, dim))       \n",
    "            res.append(mean_neighborhood_similarity(x, y, k))\n",
    "            \n",
    "        curves.append(res)\n",
    "    curves=np.array(curves)\n",
    "    return curves\n",
    "\n",
    "from joblib import Parallel,delayed\n",
    "all_curves = Parallel(n_jobs=-1)(delayed(make_curves)(n) for n in range(48*10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = np.mean( all_curves, axis=0 )\n",
    "curves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "\n",
    "plt.plot(ks, curves.T, '-', label=labels)\n",
    "\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('Similarity')\n",
    "a = 0.2\n",
    "plt.yticks(np.arange(0,1+a, a))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('dabk.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit curve\n",
    "ks = list(range(1, n_samples))\n",
    "repetitions = 30\n",
    "\n",
    "res = []\n",
    "for k in tqdm(ks):\n",
    "    this_res = []\n",
    "    for r in range(repetitions):\n",
    "        if k == 0:\n",
    "            res.append(0)\n",
    "            continue\n",
    "\n",
    "        x = np.random.randn( n_samples, dim)\n",
    "        y = np.random.randn(n_samples, dim)\n",
    "        this_res.append(mean_neighborhood_similarity(x, y, k))\n",
    "    res.append( np.mean(this_res) )\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(ks, curves.T, '-', label=labels)\n",
    "plt.plot(ks, res, 'k:', label='Lower bound')\n",
    "\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('Similarity')\n",
    "a = 0.2\n",
    "plt.yticks(np.arange(0,1+a, a))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('dabk_lowerbound.pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_aux = res.reshape( (1,-1) )\n",
    "res_ = np.repeat(res_aux,np.array(curves).shape[0],axis=0)\n",
    "print(res_.shape)\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.plot(ks, (np.array(curves).T - res_.T)/(1-res_.T), '-', label=labels)\n",
    "\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('Similarity')\n",
    "a = 0.2\n",
    "plt.yticks(np.arange(0,1+a, a))\n",
    "plt.grid()\n",
    "plt.savefig('dabk_lowerbound_scaled.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "snrs = np.linspace(-20, 60, 25)\n",
    "alphas = np.sqrt( 10**(-snrs/10) )\n",
    "res = []\n",
    "for alpha in tqdm(alphas):\n",
    "    argm = []\n",
    "    A = np.random.randn( n_samples, dim)\n",
    "    B = A + alpha*np.random.randn(n_samples, dim)\n",
    "    s = mean_neighborhood_similarity(A, B, k)\n",
    "    res.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2))\n",
    "snrs = np.array(snrs)\n",
    "res = np.array(res)\n",
    "plt.plot(snrs, res,'.-k')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('$S(A,B,20)$')\n",
    "a = 0.2\n",
    "plt.yticks(np.arange(0,1+a, a))\n",
    "plt.xticks(range(-20, 61, 10))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmin_k S(k) and min S(k) do not correlate with dimension (only in <10 dimensions)\n",
    "\n",
    "snr = 0\n",
    "alpha = 10**(-snr/20)\n",
    "dim = 100\n",
    "n_samples_list = np.array([5, 10, 20, 50, 100, 200])\n",
    "\n",
    "res = {}\n",
    "\n",
    "for n_samples in tqdm(n_samples_list):\n",
    "    argm = []\n",
    "    m = []\n",
    "\n",
    "    for k in range(1, n_samples-1):\n",
    "        x = np.random.randn( n_samples, dim)\n",
    "        A = np.random.randn( n_samples, dim)\n",
    "        B = A + alpha*np.random.randn(n_samples, dim)\n",
    "        s = mean_neighborhood_similarity(A, B, k)     \n",
    "        m.append(s)\n",
    "    \n",
    "    res[n_samples] = m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2))\n",
    "for n_samples in n_samples_list:\n",
    "    ks = list( range(1, n_samples-1) )\n",
    "    plt.plot(ks, res[n_samples], '-', label=str(n_samples))\n",
    "\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('Similarity')\n",
    "a = 0.2\n",
    "plt.yticks(np.arange(0,1+a, a))\n",
    "plt.legend(ncol=2)\n",
    "plt.grid()\n",
    "plt.savefig('dabk_nsamples.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2))\n",
    "for n_samples in n_samples_list:\n",
    "    ks = np.array(list( range(1, n_samples-1) ))\n",
    "    plt.plot(ks/n_samples, res[n_samples], '-', label=str(n_samples))\n",
    "\n",
    "plt.xlabel('$k/n$')\n",
    "plt.ylabel('Similarity')\n",
    "a = 0.2\n",
    "plt.yticks(np.arange(0,1+a, a))\n",
    "plt.legend(ncol=2)\n",
    "plt.grid()\n",
    "plt.savefig('dabk_nsamples_normalized.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmin_k S(k) and min S(k) do not correlate with dimension (only in <10 dimensions)\n",
    "\n",
    "snr = 0\n",
    "alpha = 10**(-snr/20)\n",
    "dims = list(range(2,100,1))\n",
    "n_samples = 200\n",
    "k = 20\n",
    "res = []\n",
    "argres = []\n",
    "n_repeats = 30\n",
    "rs = []\n",
    "ps = []\n",
    "for dim in tqdm(dims):\n",
    "    argm = []\n",
    "    m = []\n",
    "   \n",
    "    for n in range(n_repeats):\n",
    "        x = np.random.randn( n_samples, dim)\n",
    "        A = np.random.randn( n_samples, dim)\n",
    "        B = A + alpha*np.random.randn(n_samples, dim)\n",
    "        s = mean_neighborhood_similarity(A, B, k)     \n",
    "        \n",
    "        m.append(s)\n",
    "\n",
    "    res.append(np.mean(m))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2))\n",
    "plt.plot(dims, res, c='k')\n",
    "corr, pval = st.pearsonr(res, dims)\n",
    "plt.xlabel('dim')\n",
    "plt.ylabel('$S_g(A, B, 20)$')\n",
    "plt.xticks(range(0,110,10))\n",
    "a = 0.2\n",
    "plt.yticks(np.arange(0,1+a, a))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
